{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc   123 def\n",
      "abc   123 def\n",
      "abc   123 def\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# str = 'www.baidu.com'\n",
    "# result = re.match('www',str)\n",
    "# print(result.group())\n",
    "\n",
    "# print(result.span())\n",
    "\n",
    "# print(re.match('WWW',str)) \n",
    "# print(re.match('WWW',str,re.I)) #忽略大小写\n",
    "\n",
    "str2 = 'abc   123 def'\n",
    "print(re.match('^abc\\s.*\\d\\d\\d\\sdef$',str2).group())\n",
    "print(re.match('^abc\\s.*\\d{3}\\sdef$',str2).group())\n",
    "\n",
    "# 范匹配\n",
    "print(re.match('^abc\\s.*\\sdef$',str2).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 26), match='hello  1234567 world  Demo'>\n",
      "7\n",
      "<re.Match object; span=(0, 26), match='hello  1234567 world  Demo'>\n",
      "1234567\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "content = \"hello  1234567 world  Demo\"\n",
    "result = re.match('^hello.*(\\d+).*Demo',content)\n",
    "print(result)\n",
    "print(result.group(1))  #7    \n",
    "\n",
    "result = re.match('^hello.*?(\\d+).*Demo',content)\n",
    "print(result)\n",
    "print(result.group(1))  #1234567    .*会尽可能多的匹配内容   ?重复0次或1次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.search()  #扫描整个字符串返回第一个成功匹配的结果 , match必须匹配头部  #\n",
    "## re.findall() #搜索字符串,以列表形式返回全部能匹配的子串  ##\n",
    "## re.compile() #将正则字符串编译成正则表达式对象,以便于复用 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 123456 7890 world\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "content = \"hello 123456 world\"\n",
    "# content = re.sub('\\d+','',content)  #替换  hello  world\n",
    "# print(content) \n",
    "\n",
    "content = re.sub('(\\d+)',r'\\1 7890',content)  # 获取替换的字符串然后在后面添加内容\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1霸王别姬\n",
      "\n",
      "2肖申克的救赎\n",
      "\n",
      "3罗马假日\n",
      "\n",
      "4这个杀手不太冷\n",
      "\n",
      "5泰坦尼克号\n",
      "\n",
      "6唐伯虎点秋香\n",
      "\n",
      "7乱世佳人\n",
      "\n",
      "8魂断蓝桥\n",
      "\n",
      "9辛德勒的名单\n",
      "\n",
      "10天空之城\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import re \n",
    "#定义一个爬虫类\n",
    "class MYSpider(object):\n",
    "    def __init__(self,base_url,headers):\n",
    "        self.base_url = base_url\n",
    "        self.headers = headers\n",
    "    \n",
    "    #获取第一页内容\n",
    "    def get_onePage(self,start_num):\n",
    "        #发送请求\n",
    "        url = self.base_url.format(start_num)\n",
    "        response = requests.get(url=url,headers=self.headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.content.decode(\"utf-8\")\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "     #解析数据(利用正则表达式,筛选html)\n",
    "    def parse_onePage(self,html):\n",
    "#         pattern = re.compile('<dd>.*?board-index.*?>(\\d+)</i>.*?movie-item-info.*?>.*?<a' + '.*?title=\"(.*?)\".*?>.*?</dd>',re.S)\n",
    "        pattern = re.compile('<dd>.*?board-index.*?>(\\d+)</i>.*?movie-item-info.*?>.*?<a'\n",
    "                             +'.*?title=\"(.*?)\".*?>.*?</dd>',re.S)\n",
    "        return re.findall(pattern,html)\n",
    "    \n",
    "    #保存数据\n",
    "    def save_data(self,data):\n",
    "         for value in data:\n",
    "            list1 = []\n",
    "            for valuedata in value:\n",
    "                list1.append(valuedata)\n",
    "                \n",
    "            movestr = \"\".join(list1)+\"\\n\"\n",
    "            print(movestr)\n",
    "            \n",
    "            with open(\"movestr.txt\",\"a\",encoding=\"utf-8\")as f:\n",
    "                f.write(movestr)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://maoyan.com/board/4?offset=0{}\"\n",
    "    headers = {\n",
    "        \"User-Agent\":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "    my_spider = MYSpider(base_url,headers)\n",
    "    #1.发送请求获取整个网页的数据\n",
    "    #每个界面都要发送一个网络请求\n",
    "    html = my_spider.get_onePage(0)\n",
    "#     print(html)\n",
    "     #2.解析数据\n",
    "    result_data = my_spider.parse_onePage(html)\n",
    "#     print(result_data)\n",
    "    #3.保存数据(文件)\n",
    "    my_spider.save_data(result_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
